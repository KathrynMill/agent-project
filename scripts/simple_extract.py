#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆWordæ–‡æ¡£ä¿¡æ¯æå–å™¨
ä¸ä¾èµ–å¤–éƒ¨åº“ï¼Œæä¾›åŸºæœ¬ä¿¡æ¯å’Œæ‰‹åŠ¨å¤„ç†æŒ‡å¯¼
"""

import os
import json
import logging
from pathlib import Path
from datetime import datetime
import base64

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class SimpleDocxInfo:
    """ç®€åŒ–ç‰ˆæ–‡æ¡£ä¿¡æ¯æå–å™¨"""

    def __init__(self, docx_path: str):
        self.docx_path = Path(docx_path)
        self.file_info = {}
        self.is_readable = self._check_if_readable()

    def _check_if_readable(self) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self.docx_path.exists():
                return False

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = self.docx_path.stat().st_size
            if file_size == 0:
                return False

            # æ£€æŸ¥æ˜¯å¦æ˜¯docxæ–‡ä»¶
            if self.docx_path.suffix.lower() != '.docx':
                return False

            return True

        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def extract_basic_info(self) -> dict:
        """æå–åŸºæœ¬ä¿¡æ¯"""
        if not self.is_readable:
            return {"error": "æ–‡ä»¶ä¸å¯è¯»"}

        try:
            # åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
            stat = self.docx_path.stat()

            self.file_info = {
                "filename": self.docx_path.name,
                "file_path": str(self.docx_path),
                "file_size": stat.st_size,
                "created_time": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat()
            }

            # ä»æ–‡ä»¶åæ¨æ–­è§’è‰²
            filename = self.docx_path.name
            if "æŸ¯å¤ªå¤ª" in filename:
                self.file_info["role"] = "æŸ¯å¤ªå¤ª"
                self.file_info["role_type"] = "character"
            elif "æŸ¯å°‘çˆ·" in filename:
                self.file_info["role"] = "æŸ¯å°‘çˆ·"
                self.file_info["role_type"] = "character"
            elif "äº‘æ™´" in filename:
                self.file_info["role"] = "äº‘æ™´"
                self.file_info["role_type"] = "character"
            elif "é›¶å››" in filename:
                self.file_info["role"] = "é›¶å››"
                self.file_info["role_type"] = "character"
            elif "é›¾æ™“" in filename:
                self.file_info["role"] = "é›¾æ™“"
                self.file_info["role_type"] = "character"
            elif "æ‰‹å†Œ" in filename:
                self.file_info["role"] = "æ¸¸æˆæ‰‹å†Œ"
                self.file_info["role_type"] = "manual"
            elif "çº¿ç´¢" in filename:
                self.file_info["role"] = "çº¿ç´¢ææ–™"
                self.file_info["role_type"] = "clues"
            else:
                self.file_info["role"] = "æœªçŸ¥"
                self.file_info["role_type"] = "unknown"

            return self.file_info

        except Exception as e:
            return {"error": str(e)}

    def extract_images_info(self) -> dict:
        """æå–å›¾ç‰‡ä¿¡æ¯"""
        if not self.is_readable:
            return {"error": "æ–‡ä»¶ä¸å¯è¯»"}

        try:
            images_info = []

            # ä½¿ç”¨zipfileæ£€æŸ¥docxç»“æ„
            import zipfile
            with zipfile.ZipFile(self.docx_path, 'r') as zip_file:
                # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
                for file in zip_file.filelist:
                    if file.filename.startswith('word/media/') and \
                       file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):

                        # æå–å›¾ç‰‡æ•°æ®
                        image_data = zip_file.read(file.filename)
                        image_info = {
                            "filename": os.path.basename(file.filename),
                            "internal_path": file.filename,
                            "size_bytes": len(image_data),
                            "description": self._generate_image_description(file.filename),
                            "extracted": True
                        }

                        # è½¬æ¢ä¸ºbase64ï¼ˆå¯é€‰ï¼Œç”¨äºä¿å­˜å›¾ç‰‡ä¿¡æ¯ï¼‰
                        try:
                            image_info["base64"] = base64.b64encode(image_data).decode('utf-8')
                        except:
                            image_info["base64"] = ""

                        images_info.append(image_info)

            return {
                "image_count": len(images_info),
                "images": images_info
            }

        except Exception as e:
            logger.error(f"æå–å›¾ç‰‡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e), "image_count": 0}

    def _generate_image_description(self, filename: str) -> str:
        """ç”Ÿæˆå›¾ç‰‡æè¿°"""
        base_name = os.path.basename(filename)

        if "æŸ¯å¤ªå¤ª" in base_name:
            return "æŸ¯å¤ªå¤ªçš„ç…§ç‰‡/è¯ä»¶ç…§"
        elif "æŸ¯å°‘çˆ·" in base_name:
            return "æŸ¯å°‘çˆ·çš„ç…§ç‰‡/è¯ä»¶ç…§"
        elif "äº‘æ™´" in base_name:
            return "äº‘æ™´çš„ç…§ç‰‡/è¯ä»¶ç…§"
        elif "é›¶å››" in base_name:
            return "é›¶å››çš„ç…§ç‰‡/è¯ä»¶ç…§"
        elif "é›¾æ™“" in base_name:
            return "é›¾æ™“çš„ç…§ç‰‡/è¯ä»¶ç…§"
        elif "æ‰‹å†Œ" in base_name:
            return "æ¸¸æˆæ‰‹å†Œä¸­çš„å›¾ç‰‡/è¯´æ˜å›¾"
        elif "çº¿ç´¢" in base_name:
            return f"çº¿ç´¢å›¾ç‰‡ - {base_name}"
        elif "æ—¶é—´çº¿" in base_name:
            return "æ—¶é—´çº¿/æ—¶é—´è½´å›¾ç‰‡"
        elif "åœ°å›¾" in base_name or "å¹³é¢å›¾" in base_name:
            return "åœ°å›¾/å¹³é¢å›¾"
        else:
            return f"å‰§æƒ…ç›¸å…³å›¾ç‰‡ - {base_name}"

    def get_manual_conversion_guide(self) -> str:
        """è·å–æ‰‹åŠ¨è½¬æ¢æŒ‡å¯¼"""
        return f"""
æ‰‹åŠ¨è½¬æ¢æŒ‡å¯¼ - {self.docx_path.name}

æ­¥éª¤1: æå–æ–‡æœ¬å†…å®¹
- æ‰“å¼€Wordæ–‡æ¡£
- å…¨é€‰æ–‡æœ¬ (Ctrl+A)
- å¤åˆ¶ (Ctrl+C)
- ç²˜è´´åˆ°æ–‡æœ¬æ–‡ä»¶ä¸­

æ­¥éª¤2: æå–å›¾ç‰‡å†…å®¹
- å³é”®ç‚¹å‡»å›¾ç‰‡ â†’ å¦å­˜ä¸º
- ä¿å­˜ä¸º PNG æˆ– JPG æ ¼å¼
- è®°å½•å›¾ç‰‡å¯¹åº”çš„æ–‡å­—è¯´æ˜

æ­¥éª¤3: æå–å…³é”®ä¿¡æ¯
- ç¡®å®šè§’è‰²å§“å
- è¯†åˆ«å…³é”®çº¿ç´¢
- æ ‡è®°æ—¶é—´çº¿
- è®°å½•é‡è¦å¯¹è¯

å»ºè®®è¾“å‡ºæ ¼å¼:
è§’è‰²: {self.file_info.get("role", "æœªçŸ¥")}
æ–‡æœ¬å†…å®¹: [ç²˜è´´çš„æ–‡æœ¬]
å›¾ç‰‡: [å›¾ç‰‡æè¿°å’Œæ–‡ä»¶å]
å…³é”®çº¿ç´¢: [åˆ—å‡ºå…³é”®çº¿ç´¢]
æ—¶é—´çº¿: [é‡è¦æ—¶é—´ç‚¹]
"""


def analyze_all_files(docx_files):
    """åˆ†ææ‰€æœ‰docxæ–‡ä»¶"""
    print("\n" + "="*60)
    print("Wordæ–‡æ¡£åˆ†ææŠ¥å‘Š")
    print("="*60)

    file_analysis = []
    character_files = {}
    manual_files = []
    clues_files = []

    for docx_file in docx_files:
        if not os.path.exists(docx_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docx_file}")
            continue

        print(f"\nğŸ“„ åˆ†ææ–‡ä»¶: {os.path.basename(docx_file)}")
        analyzer = SimpleDocxInfo(docx_file)

        # åŸºæœ¬ä¿¡æ¯
        basic_info = analyzer.extract_basic_info()
        if "error" in basic_info:
            print(f"âŒ é”™è¯¯: {basic_info['error']}")
            continue

        print(f"   è§’è‰²: {basic_info['role']}")
        print(f"   ç±»å‹: {basic_info['role_type']}")
        print(f"   å¤§å°: {basic_info['file_size']} bytes")

        # å›¾ç‰‡ä¿¡æ¯
        images_info = analyzer.extract_images_info()
        if "error" not in images_info:
            print(f"   å›¾ç‰‡: {images_info['image_count']} å¼ ")
            for img in images_info['images'][:3]:  # åªæ˜¾ç¤ºå‰3å¼ 
                print(f"      - {img['description']}")
        else:
            print(f"   å›¾ç‰‡: æ£€æŸ¥å¤±è´¥")

        # åˆ†ç±»å­˜å‚¨
        analysis_data = {
            "file_info": basic_info,
            "images_info": images_info
        }

        if basic_info['role_type'] == 'character':
            character_files[basic_info['role']] = analysis_data
        elif basic_info['role_type'] == 'manual':
            manual_files.append(analysis_data)
        elif basic_info['role_type'] == 'clues':
            clues_files.append(analysis_data)

        file_analysis.append(analysis_data)

    # è¾“å‡ºæ€»ç»“
    print("\n" + "="*60)
    print("åˆ†ææ€»ç»“")
    print("="*60)
    print(f"æ€»æ–‡ä»¶æ•°: {len(file_analysis)}")
    print(f"è§’è‰²æ–‡ä»¶: {len(character_files)}")
    print(f"æ‰‹å†Œæ–‡ä»¶: {len(manual_files)}")
    print(f"çº¿ç´¢æ–‡ä»¶: {len(clues_files)}")

    print("\nè§’è‰²åˆ—è¡¨:")
    for role in character_files.keys():
        print(f"  - {role}")

    # ç”Ÿæˆå¤„ç†å»ºè®®
    print("\nğŸ“‹ æ•°æ®å¤„ç†å»ºè®®:")
    print("1. å°†æ‰€æœ‰è§’è‰²å‰§æœ¬åˆå¹¶æˆä¸€ä¸ªå®Œæ•´æ–‡æœ¬")
    print("2. æå–æ‰€æœ‰å…³é”®å›¾ç‰‡å¹¶æ ‡æ³¨è¯´æ˜")
    print("3. æ•´ç†æ—¶é—´çº¿å’Œå…³é”®çº¿ç´¢")
    print("4. åˆ›å»ºæ ‡å‡†è®­ç»ƒæ•°æ®æ ¼å¼")

    return {
        "all_files": file_analysis,
        "characters": character_files,
        "manuals": manual_files,
        "clues": clues_files
    }


def create_training_sample_template():
    """åˆ›å»ºè®­ç»ƒæ•°æ®æ¨¡æ¿"""
    template = {
        "script_id": "æŸ¯å®¶åº„å›­è°‹æ€æ¡ˆ_001",
        "title": "æŸ¯å®¶åº„å›­è°‹æ€æ¡ˆ",
        "original_script": "è¿™é‡Œæ”¾å…¥å®Œæ•´å‰§æœ¬æ–‡æœ¬...",
        "compressed_script": "è¿™é‡Œæ”¾å…¥å‹ç¼©åçš„å‰§æœ¬...",
        "compression_ratio": 0.6,
        "compression_level": "medium",
        "logic_integrity": 0.9,
        "story_coherence": 0.85,
        "playability_score": 0.88,
        "preserved_elements": [
            "æŸ¯å¤ªå¤ªçš„ç§˜å¯†",
            "é›¶å››çš„çœŸå®èº«ä»½",
            "å‡¶æ¡ˆæ—¶é—´çº¿",
            "å…³é”®è¯æ®ç…§ç‰‡"
        ],
        "key_images": [
            {
                "description": "æ¡ˆå‘ç°åœºç…§ç‰‡",
                "filename": "scene_photo_01.jpg",
                "importance": "high"
            }
        ],
        "metadata": {
            "created_date": datetime.now().isoformat(),
            "version": "v1.0",
            "analyzer": "manual"
        }
    }

    # ä¿å­˜æ¨¡æ¿
    output_dir = Path("/home/ubt/æ¡Œé¢/agent-project/data/samples")
    output_dir.mkdir(parents=True, exist_ok=True)

    template_file = output_dir / "training_sample_template.json"
    with open(template_file, 'w', encoding='utf-8') as f:
        json.dump(template, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ è®­ç»ƒæ•°æ®æ¨¡æ¿å·²åˆ›å»º: {template_file}")
    print("è¯·æ ¹æ®æ¨¡æ¿æ ¼å¼å¡«å……æ‚¨çš„å‰§æœ¬æ•°æ®")


def main():
    """ä¸»å‡½æ•°"""
    docx_files = [
        "/home/ubt/æ¡Œé¢/agent-project/01 ç»·å¸¦å¥³äºº æŸ¯å¤ªå¤ª_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/02 å¹´è½»ç”·å­ æŸ¯å°‘çˆ·_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/03 å¥³ä»† äº‘æ™´_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/04 èƒ¡èŒ¬ç”·äºº é›¶å››_QQæµè§ˆå™¨è½¬æ ¼å¼ (1).docx",
        "/home/ubt/æ¡Œé¢/agent-project/05 æ´‹è£™å¥³å­ é›¾æ™“_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/æ‰‹å†Œ_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/çº¿ç´¢_QQæµè§ˆå™¨è½¬æ ¼å¼.docx"
    ]

    # åˆ†ææ–‡ä»¶
    analysis_result = analyze_all_files(docx_files)

    # åˆ›å»ºè®­ç»ƒæ•°æ®æ¨¡æ¿
    create_training_sample_template()

    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
    print(f"1. æ‰‹åŠ¨æå–æ¯ä¸ªWordæ–‡ä»¶çš„æ–‡æœ¬å†…å®¹")
    print(f"2. æå–å¹¶ä¿å­˜æ‰€æœ‰å…³é”®å›¾ç‰‡")
    print(f"3. ä½¿ç”¨è®­ç»ƒæ•°æ®æ¨¡æ¿åˆ›å»ºæ ‡å‡†æ ¼å¼")
    print(f"4. è¿è¡Œ: python scripts/create_training_data.py")


if __name__ == "__main__":
    main()