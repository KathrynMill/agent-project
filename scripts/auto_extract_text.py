#!/usr/bin/env python3
"""
è‡ªåŠ¨æå–Wordæ–‡æ¡£æ–‡æœ¬å†…å®¹
ä½¿ç”¨python-docxåº“æå–æ–‡æœ¬å’Œå›¾ç‰‡ä¿¡æ¯
"""

import os
import sys
import json
import logging
import base64
from pathlib import Path
from datetime import datetime
import zipfile
from io import BytesIO

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥python-docx
try:
    from docx import Document
    from PIL import Image
    DOCX_AVAILABLE = True
    logger.info("python-docx åº“å¯ç”¨")
except ImportError:
    DOCX_AVAILABLE = False
    logger.warning("python-docx åº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")


class DocxTextExtractor:
    """Wordæ–‡æ¡£æ–‡æœ¬æå–å™¨"""

    def __init__(self, docx_path: str):
        self.docx_path = Path(docx_path)
        self.content = {
            "text": "",
            "paragraphs": [],
            "images": [],
            "metadata": {}
        }
        self.success = False

    def extract_content(self):
        """æå–æ–‡æ¡£å†…å®¹"""
        try:
            if DOCX_AVAILABLE:
                self._extract_with_docx()
            else:
                self._extract_with_zipfile()

            self.success = True
            logger.info(f"æˆåŠŸæå–å†…å®¹: {self.docx_path.name}")

        except Exception as e:
            logger.error(f"æå–å¤±è´¥: {e}")
            self.success = False

    def _extract_with_docx(self):
        """ä½¿ç”¨python-docxæå–"""
        doc = Document(self.docx_path)

        # æå–æ®µè½
        paragraphs = []
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                paragraphs.append(paragraph.text.strip())

        self.content["text"] = "\n".join(paragraphs)
        self.content["paragraphs"] = paragraphs

        # æå–å›¾ç‰‡
        self._extract_images_from_docx()

    def _extract_with_zipfile(self):
        """ä½¿ç”¨zipfileæå–ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        with zipfile.ZipFile(self.docx_path, 'r') as zip_file:
            # è¯»å–æ–‡æ¡£å†…å®¹
            document_xml = zip_file.read('word/document.xml')

            # ç®€å•çš„XMLæ–‡æœ¬æå–
            import re
            text_content = re.sub(r'<[^>]+>', ' ', document_xml.decode('utf-8'))
            text_content = ' '.join(text_content.split())

            # æå–æ®µè½æ–‡æœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰
            paragraphs = []
            text_blocks = re.findall(r'([^<>\n]{10,100})', text_content)
            for block in text_blocks:
                if block.strip() and len(block) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                    paragraphs.append(block.strip())

            self.content["text"] = "\n".join(paragraphs)
            self.content["paragraphs"] = paragraphs

            # æå–å›¾ç‰‡ä¿¡æ¯
            self._extract_images_from_zipfile(zip_file)

    def _extract_images_from_docx(self):
        """ä»docxæå–å›¾ç‰‡"""
        if not DOCX_AVAILABLE:
            return

        doc = Document(self.docx_path)
        image_count = 0

        for rel in doc.part.rels.iter():
            if "image" in rel.target_ref:
                try:
                    image_part = doc.part.get_part(rel.target_ref)
                    image_data = image_part.blob

                    # å°è¯•è¯†åˆ«å›¾ç‰‡ç±»å‹
                    img = Image.open(BytesIO(image_data))
                    width, height = img.size
                    format_name = img.format

                    images_info = {
                        "index": image_count + 1,
                        "filename": f"image_{image_count + 1}.{format_name.lower()}" if format_name else f"image_{image_count + 1}.jpg",
                        "width": width,
                        "height": height,
                        "format": format_name,
                        "size": len(image_data),
                        "base64": base64.b64encode(image_data).decode('utf-8')
                    }

                    self.content["images"].append(images_info)
                    image_count += 1

                except Exception as e:
                    logger.warning(f"å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")

    def _extract_images_from_zipfile(self, zip_file):
        """ä»zipfileæå–å›¾ç‰‡ä¿¡æ¯"""
        images_info = []

        try:
            for file in zip_file.filelist:
                if file.filename.startswith('word/media/') and \
                   file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):

                    image_data = zip_file.read(file.filename)

                    try:
                        img = Image.open(BytesIO(image_data))
                        width, height = img.size
                        format_name = img.format if img.format else "Unknown"
                    except:
                        # æ— æ³•è¯†åˆ«å›¾ç‰‡æ ¼å¼
                        width = height = 0
                        format_name = "Unknown"

                    image_info = {
                        "filename": os.path.basename(file.filename),
                        "internal_path": file.filename,
                        "width": width,
                        "height": height,
                        "format": format_name,
                        "size": len(image_data),
                        "base64": base64.b64encode(image_data).decode('utf-8')
                    }

                    images_info.append(image_info)

        except Exception as e:
            logger.warning(f"ä»zipfileæå–å›¾ç‰‡å¤±è´¥: {e}")

        self.content["images"] = images_info

    def analyze_content(self):
        """åˆ†ææå–çš„å†…å®¹"""
        text = self.content.get("text", "")
        images = self.content.get("images", [])

        # åŸºç¡€ç»Ÿè®¡
        char_count = len(text)
        word_count = len(text.split())
        paragraph_count = len(self.content.get("paragraphs", []))

        # è§’è‰²æ¨æ–­ï¼ˆä»æ–‡ä»¶åï¼‰
        filename = self.docx_path.name
        role = "æœªçŸ¥"
        if "æŸ¯å¤ªå¤ª" in filename:
            role = "æŸ¯å¤ªå¤ª"
        elif "æŸ¯å°‘çˆ·" in filename:
            role = "æŸ¯å°‘çˆ·"
        elif "äº‘æ™´" in filename:
            role = "äº‘æ™´"
        elif "é›¶å››" in filename:
            role = "é›¶å››"
        elif "é›¾æ™“" in filename:
            role = "é›¾æ™“"
        elif "æ‰‹å†Œ" in filename:
            role = "æ¸¸æˆæ‰‹å†Œ"
        elif "çº¿ç´¢" in filename:
            role = "çº¿ç´¢ææ–™"

        # å†…å®¹ç‰¹å¾åˆ†æ
        features = {
            "has_dialogue": "ï¼š" in text or "\"" in text,
            "has_timeline": any(word in text for word in ["æ—¶é—´", "ç‚¹", "åˆ†é’Ÿ", "å°æ—¶"]),
            "has_clues": any(word in text for word in ["çº¿ç´¢", "è¯æ®", "ç§˜å¯†"]),
            "has_death": any(word in text for word in ["æ­»äº¡", "æ­»", "è¢«æ€"])
        }

        self.content["metadata"] = {
            "role": role,
            "char_count": char_count,
            "word_count": word_count,
            "paragraph_count": paragraph_count,
            "image_count": len(images),
            "file_size": self.docx_path.stat().st_size,
            "features": features,
            "estimated_duration_hours": max(1, char_count / 3000),  # ç®€å•ä¼°ç®—
            "complexity": "medium" if char_count > 2000 else "simple"
        }

    def print_summary(self):
        """æ‰“å°æå–æ‘˜è¦"""
        if not self.success:
            print(f"âŒ æå–å¤±è´¥: {self.docx_path}")
            return

        print(f"ğŸ“„ æ–‡ä»¶: {self.docx_path.name}")
        print(f"ğŸ­ è§’è‰²: {self.content['metadata']['role']}")
        print(f"ğŸ“ å­—æ•°: {self.content['metadata']['char_count']}")
        print(f"ğŸ“– æ®µè½: {self.content['metadata']['paragraph_count']}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡: {self.content['metadata']['image_count']} å¼ ")

        if self.content['metadata']['features']['has_dialogue']:
            print("ğŸ’¬ åŒ…å«å¯¹è¯")
        if self.content['metadata']['features']['has_timeline']:
            print("â° åŒ…å«æ—¶é—´çº¿")
        if self.content['metadata']['features']['has_clues']:
            print("ğŸ” åŒ…å«çº¿ç´¢")
        if self.content['metadata']['features']['has_death']:
            print("ğŸ’€ åŒ…å«æ­»äº¡æƒ…èŠ‚")

        # æ˜¾ç¤ºå‰å‡ æ®µå†…å®¹
        print("\nğŸ“– æ–‡æœ¬é¢„è§ˆ (å‰3æ®µ):")
        for i, paragraph in enumerate(self.content['paragraphs'][:3]):
            print(f"  {i+1}. {paragraph[:100]}{'...' if len(paragraph) > 100 else ''}")


def process_all_files():
    """å¤„ç†æ‰€æœ‰docxæ–‡ä»¶"""
    docx_files = [
        "/home/ubt/æ¡Œé¢/agent-project/01 ç»·å¸¦å¥³äºº æŸ¯å¤ªå¤ª_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/02 å¹´è½»ç”·å­ æŸ¯å°‘çˆ·_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/03 å¥³ä»† äº‘æ™´_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/04 èƒ¡èŒ¬ç”·äºº é›¶å››_QQæµè§ˆå™¨è½¬æ ¼å¼ (1).docx",
        "/home/ubt/æ¡Œé¢/agent-project/05 æ´‹è£™å¥³å­ é›¾æ™“_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/æ‰‹å†Œ_QQæµè§ˆå™¨è½¬æ ¼å¼.docx",
        "/home/ubt/æ¡Œé¢/agent-project/çº¿ç´¢_QQæµè§ˆå™¨è½¬æ ¼å¼.docx"
    ]

    print("ğŸ­ æŸ¯å®¶åº„å›­è°‹æ€æ¡ˆ - è‡ªåŠ¨æ–‡æœ¬æå–")
    print("="*50)

    extracted_data = {
        "title": "æŸ¯å®¶åº„å›­è°‹æ€æ¡ˆ",
        "extracted_at": datetime.now().isoformat(),
        "files": {},
        "full_text": "",
        "all_images": [],
        "metadata": {}
    }

    character_scripts = {}
    manual_data = None
    clues_data = None

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for docx_file in docx_files:
        if not os.path.exists(docx_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docx_file}")
            continue

        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(docx_file)}")
        extractor = DocxTextExtractor(docx_file)
        extractor.extract_content()
        extractor.analyze_content()
        extractor.print_summary()

        if extractor.success:
            role = extractor.content['metadata']['role']
            file_data = {
                "text": extractor.content['text'],
                "metadata": extractor.content['metadata'],
                "images": extractor.content['images']
            }

            extracted_data['files'][os.path.basename(docx_file)] = file_data

            # åˆ†ç±»å­˜å‚¨
            if role in ['æŸ¯å¤ªå¤ª', 'æŸ¯å°‘çˆ·', 'äº‘æ™´', 'é›¶å››', 'é›¾æ™“']:
                character_scripts[role] = file_data
            elif role == 'æ¸¸æˆæ‰‹å†Œ':
                manual_data = file_data
            elif role == 'çº¿ç´¢ææ–™':
                clues_data = file_data

            # æ·»åŠ åˆ°å®Œæ•´æ–‡æœ¬
            if extractor.content['text']:
                extracted_data['full_text'] += f"\n\n=== {role} ===\n"
                extracted_data['full_text'] += extractor.content['text']

            # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
            if extractor.content['images']:
                extracted_data['all_images'].extend(extractor.content['images'])

    # ç»Ÿè®¡ä¿¡æ¯
    extracted_data['metadata'] = {
        'total_files': len(extracted_data['files']),
        'character_count': len(character_scripts),
        'has_manual': manual_data is not None,
        'has_clues': clues_data is not None,
        'total_images': len(extracted_data['all_images']),
        'full_text_length': len(extracted_data['full_text'])
    }

    # ä¿å­˜å®Œæ•´æå–æ•°æ®
    output_dir = Path("/home/ubt/æ¡Œé¢/agent-project/data/extracted")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜è¯¦ç»†æ•°æ®
    full_output_file = output_dir / "ke_mansion_murder_full.json"
    with open(full_output_file, 'w', encoding='utf-8') as f:
        json.dump(extracted_data, f, ensure_ascii=False, indent=2)

    # ä¿å­˜åˆ†ç±»æ•°æ®
    extracted_data['character_scripts'] = character_scripts
    extracted_data['game_manual'] = manual_data
    extracted_data['clues'] = clues_data

    simple_output_file = output_dir / "ke_mansion_murder_simple.json"
    with open(simple_output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "title": extracted_data['title'],
            "character_scripts": {role: data['text'] for role, data in character_scripts.items()},
            "game_manual": manual_data['text'] if manual_data else "",
            "clues": clues_data['text'] if clues_data else "",
            "full_text": extracted_data['full_text'],
            "metadata": extracted_data['metadata']
        }, f, ensure_ascii=False, indent=2)

    print("\n" + "="*50)
    print("âœ… æå–å®Œæˆï¼")
    print("="*50)
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»æ–‡ä»¶æ•°: {extracted_data['metadata']['total_files']}")
    print(f"   è§’è‰²æ•°é‡: {extracted_data['metadata']['character_count']}")
    print(f"   æ‰‹å†Œæ–‡ä»¶: {'æœ‰' if extracted_data['metadata']['has_manual'] else 'æ— '}")
    print(f"   çº¿ç´¢æ–‡ä»¶: {'æœ‰' if extracted_data['metadata']['has_clues'] else 'æ— '}")
    print(f"   æ€»å›¾ç‰‡æ•°: {extracted_data['metadata']['total_images']}")
    print(f"   æ–‡æœ¬é•¿åº¦: {extracted_data['metadata']['full_text_length']} å­—ç¬¦")

    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   å®Œæ•´æ•°æ®: {full_output_file}")
    print(f"   ç®€åŒ–æ•°æ®: {simple_output_file}")

    return extracted_data


def create_compressed_sample(full_data):
    """åˆ›å»ºå‹ç¼©æ ·æœ¬ç¤ºä¾‹"""
    print("\nğŸ¯ åˆ›å»ºå‹ç¼©æ ·æœ¬ç¤ºä¾‹...")

    full_text = full_data['full_text']
    if not full_text:
        print("âŒ æ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œæ— æ³•åˆ›å»ºå‹ç¼©æ ·æœ¬")
        return

    # ç®€å•çš„å‹ç¼©é€»è¾‘ï¼šåŸºäºå…³é”®è¯åˆ†æ®µå‹ç¼©
    sections = full_text.split('\n=== ')
    compressed_sections = []

    for section in sections:
        if not section.strip():
            continue

        lines = section.split('\n')
        if len(lines) > 10:
            # ä¿ç•™å‰å‡ è¡Œå’Œæœ€åå‡ è¡Œï¼Œå‹ç¼©ä¸­é—´å†…å®¹
            if len(lines) > 20:
                compressed_section = '\n'.join(lines[:3] + ['...'] + lines[-2:])
            else:
                # ç®€å•å‹ç¼©
                compressed_section = '\n'.join(lines[:len(lines)//2])
        else:
            compressed_section = section

        compressed_sections.append(compressed_section)

    compressed_text = '\n\n'.join(compressed_sections)

    # è®¡ç®—å‹ç¼©æ¯”ä¾‹
    original_length = len(full_text)
    compressed_length = len(compressed_text)
    compression_ratio = compressed_length / original_length if original_length > 0 else 0.6

    # åˆ›å»ºè®­ç»ƒæ ·æœ¬
    training_sample = {
        "script_id": "ke_murder_compressed_001",
        "title": "æŸ¯å®¶åº„å›­è°‹æ€æ¡ˆ",
        "original_script": full_text,
        "compressed_script": compressed_text,
        "compression_ratio": compression_ratio,
        "compression_level": "medium" if compression_ratio > 0.6 else "heavy",
        "logic_integrity": 0.8,  # å‡è®¾å€¼
        "story_coherence": 0.75,  # å‡è®¾å€¼
        "playability_score": 0.82,  # å‡è®¾å€¼
        "preserved_elements": [
            "è§’è‰²åŸºæœ¬ä¿¡æ¯",
            "æ¡ˆä»¶æ ¸å¿ƒäº‹å®",
            "å…³é”®æ—¶é—´ç‚¹"
        ],
        "key_images": full_data['all_images'][:5],  # å‰5å¼ å›¾ç‰‡
        "metadata": {
            "created_date": datetime.now().isoformat(),
            "compression_method": "automatic",
            "version": "v1.0"
        }
    }

    # ä¿å­˜å‹ç¼©æ ·æœ¬
    output_dir = Path("/home/ubt/æ¡Œé¢/agent-project/data/extracted")
    sample_file = output_dir / "training_sample_compressed.json"

    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(training_sample, f, ensure_ascii=False, indent=2)

    print(f"ğŸ¯ å‹ç¼©æ ·æœ¬å·²åˆ›å»º: {sample_file}")
    print(f"   åŸå§‹é•¿åº¦: {original_length} å­—ç¬¦")
    print(f"   å‹ç¼©é•¿åº¦: {compressed_length} å­—ç¬¦")
    print(f"   å‹ç¼©æ¯”ä¾‹: {compression_ratio:.3f}")

    return training_sample


def main():
    """ä¸»å‡½æ•°"""
    try:
        # æå–æ‰€æœ‰æ–‡ä»¶å†…å®¹
        extracted_data = process_all_files()

        # åˆ›å»ºå‹ç¼©æ ·æœ¬
        if extracted_data['full_text']:
            create_compressed_sample(extracted_data)

        print(f"\nğŸš€ æ•°æ®æå–å®Œæˆï¼")
        print(f"ç°åœ¨ä½ å¯ä»¥:")
        print(f"1. æŸ¥çœ‹æå–çš„æ–‡æœ¬å†…å®¹")
        print(f"2. ä½¿ç”¨å‹ç¼©æ ·æœ¬è¿›è¡Œæµ‹è¯•")
        print(f"3. æ ¹æ®éœ€è¦æ‰‹åŠ¨è°ƒæ•´è´¨é‡è¯„åˆ†")
        print(f"4. å¼€å§‹æ¨¡å‹è®­ç»ƒ")

    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()